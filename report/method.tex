\subsection{Data Used}
We used the October 12, 2012  Presidential Debate Corpus care of Boydstun et al. The full version is roughly 70 MB and consists of  $193286$ unique user entries collected from $3641$ users.  The features of each reaction are tied to the user making the reaction, and include demographic attributes as well as preferences on political parties, issues, candidates, and campaigns.  In addition, we used the timestamped and "coded" transcript of the October 12, 2012 Presidential Debate, which consists of 1,173 clauses and corresponding visible topic features.
For LDA we used \emph{gensim}, a python library developed by Radim Rehurek \cite{gensim}

\subsection{Inherent Bias}
The reactions dataset that we are using consists of the reactions of college students to the 2012 presidential debates. Users registered reactions as input to a mobile application while watching the debate live and document a feeling of agreement, disagreement, spin, or dodge with a candidate's statement.  Because the data reflects a subset of citizens who tend to be younger and more progressive, we feel it is necessary to state as such at the outset. Any collective reference to respondents will be framed by this bias. In addition, we feel that the results highlight this bias, as described in the results section of this report.

\subsection{Expected Results}
Since LDA can be thought of as a dimension reduction technique, ideally we wanted to feed in a set of documents (as described below) and get some output back that described the principal components of these documents. For example, these components can be expressed for documents representing users like "For a document representing User A, they were primarily represented by features X, Y and Z."

\subsection{Evaluation Technique}
LDA is an unsupervised learning technique, which makes evaluations implicitly more difficult since there's no comparative standard to hold a model up to.  However, given the limited response choices offered to the participant (choices were selected based on a questionnaire), we were guided by reasonable expectations of the resulting topics.

Since this was an investigative project based on "real" datasets, a strictly qualitative or comparative analysis did not feel correct. Instead, we chose to deem LDA a success for this corpus if it returned topics that varied sufficiently in either feature dimensionality (different features lending different strength to a given topic) or feature interaction between one or more topic features.

\subsection{Pre-Processing}
The set of reaction data exists as a comma separated value (CSV) file, where each atomic entry is separated by a carriage return, and each value within an entry is separated by a comma. For our purposes, this file can reasonably be thought of as a $MxN$ matrix, where $M$ is the number of entries and $N$ is the max number of values that an single entry could have.

A \emph{document} is then a join operation over this matrix, where document $k$ is formed by the joining of all rows $m \in M$ such that index $m,n$ is some collective identifier.

\emph{Example}: \emph{userID} is the first column of the matrix, and we wish to form documents that correspond to each user that participated in the questionnaire. Then a document is $\forall m \in M | n = ID ,C_{m,n}$ In layman's terms, this is just every row with a matching userID.\\

To attach debate topic information to participant-level reaction information, we mapped reactions to the visible features (e.g., question topic, answer topic, framework, and tone) of each corresponding statement.  Visible topic features were incorporated as features for each reaction item based on the reaction occuring between the start and end time of the statement as well as a match of the speaker.   Before correlation,  we collapsed the clause units into full statements for a speaker, thereby extending the acceptable time range to allow for potential delays based on user input and media source.  The resulting coded dataset holds the most representative element of each feature: question topic, answer topic, framework, and tone, and resulted in 58 statement units.

